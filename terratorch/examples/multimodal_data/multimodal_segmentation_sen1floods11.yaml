# lightning.pytorch==2.1.1
seed_everything: 0
trainer:
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: 16-mixed
  logger: true
  callbacks:
    - class_path: RichProgressBar
    - class_path: LearningRateMonitor
      init_args:
        logging_interval: epoch
    - class_path: EarlyStopping
      init_args:
        monitor: val/loss
        patience: 40

  max_epochs: 100
  check_val_every_n_epoch: 1
  log_every_n_steps: 50
  enable_checkpointing: True
  default_root_dir: output/multimodal_prithvi_sen1floods11/

data:
  class_path: terratorch.datamodules.GenericMultiModalDataModule
  init_args:
    task: 'segmentation'
    batch_size: 16
    num_workers: 4
    modalities: # Define names of modalities
      - S2L1C
      - S1
    rgb_modality: S2L1C # If not provided, uses first modality
    rgb_indices:
      - 3
      - 2
      - 1

    # Data roots are defined as dicts with modalities as keys
    train_data_root:
      S2L1C: sen1floods11/data/S2L1CHand
      S1: sen1floods11/data/S1GRDHand
    train_label_data_root: sen1floods11/data/LabelHand
    val_data_root:
      S2L1C: sen1floods11/data/S2L1CHand
      S1: sen1floods11/data/S1GRDHand
    val_label_data_root: sen1floods11/data/LabelHand
    test_data_root:
      S2L1C: sen1floods11/data/S2L1CHand
      S1: sen1floods11/data/S1GRDHand
    test_label_data_root: sen1floods11/data/LabelHand

    train_split: sen1floods11/splits/flood_train_data.txt
    val_split: sen1floods11/splits/flood_valid_data.txt
    test_split: sen1floods11/splits/flood_test_data.txt

    allow_substring_file_names: True
    image_grep:
      S2L1C: "*_S2Hand.tif"
      S1: "*_S1Hand.tif"
    label_grep: "*_LabelHand.tif"
    no_label_replace: -1
    no_data_replace: 0
    concat_bands: true # Concatenate modalities along band dim for single-modal models like Prithvi

    # Define standardization values as dicts
    means:
      S2L1C:
        - 1626.916
        - 1396.035
        - 1364.061
        - 1218.228
        - 1466.073
        - 2386.903
        - 2845.613
        - 2622.958
        - 3077.482
        - 486.874
        - 63.779
        - 2030.648
        - 1179.166
      S1:
        - -10.184
        - -16.895

    stds:
      S2L1C:
        - 700.171
        - 739.095
        - 735.248
        - 864.937
        - 776.880
        - 921.368
        - 1084.373
        - 1022.634
        - 1196.443
        - 336.611
        - 143.999
        - 980.871
        - 764.608
      S1:
        - 4.255
        - 5.291

    num_classes: 2

    # Transforms are shared between all image modalities (e.g. same crop area)
    train_transform:
      - class_path: albumentations.RandomCrop
        init_args:
          height: 224
          width: 224
      - class_path: albumentations.D4
      - class_path: albumentations.pytorch.transforms.ToTensorV2


model:
  class_path: terratorch.tasks.SemanticSegmentationTask
  init_args:
    model_factory: EncoderDecoderFactory
    model_args:
      backbone: prithvi_eo_v2_300
      backbone_pretrained: false
      backbone_bands:
        - COASTAL_AEROSOL
        - BLUE
        - GREEN
        - RED
        - RED_EDGE_1
        - RED_EDGE_2
        - RED_EDGE_3
        - NIR_BROAD
        - NIR_NARROW
        - WATER_VAPOR
        - CIRRUS
        - SWIR_1
        - SWIR_2
        - VV
        - VH
      decoder: FCNDecoder
      decoder_num_convs: 4
      decoder_channels: 256
      num_classes: 2
      head_dropout: 0.1
      head_channel_list:
        - 256
    loss: dice
    ignore_index: -1
    freeze_backbone: false
    freeze_decoder: false

optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 6.e-5
    weight_decay: 0.05
lr_scheduler:
  class_path: ReduceLROnPlateau
  init_args:
    monitor: val/loss